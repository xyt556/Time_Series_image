{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87f4ce3e-551d-4cc2-bdd7-6afd658eebc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"       \\ntrend: tells the trend (increasing, decreasing or no trend)\\n        h: True (if trend is present) or False (if trend is absence)\\n        p: p-value of the significance test\\n        z: normalized test statistics\\n        Tau: Kendall Tau\\n        s: Mann-Kendal's score\\n        var_s: Variance S\\n        slope: Theil-Sen estimator/slope\\n        intercept: intercept of Kendall-Theil Robust Line\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''       \n",
    "trend: tells the trend (increasing, decreasing or no trend)\n",
    "        h: True (if trend is present) or False (if trend is absence)\n",
    "        p: p-value of the significance test\n",
    "        z: normalized test statistics\n",
    "        Tau: Kendall Tau\n",
    "        s: Mann-Kendal's score\n",
    "        var_s: Variance S\n",
    "        slope: Theil-Sen estimator/slope\n",
    "        intercept: intercept of Kendall-Theil Robust Line\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc492b47-8e0c-4808-b725-ecd8c53377da",
   "metadata": {},
   "source": [
    "# 1.导入python包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5488c7a1-31c7-4fbd-ae12-adc2069fba80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "import numpy as np\n",
    "import pymannkendall as mk\n",
    "import os \n",
    "import rasterio as ras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f376eb7-c216-4763-9240-5c9d5dc5b207",
   "metadata": {},
   "source": [
    "# 2.获取所有的影像路径，按照从小到大年份排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c09b05b9-8c1d-470d-91a6-3c0e108833cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path1=r\"./NPP\"\n",
    "filepaths=[]\n",
    "for file in os.listdir(path1):\n",
    "    filepath1=os.path.join(path1,file)\n",
    "    filepaths.append(filepath1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86164f98-b093-4cbf-a5d9-4de7c66a0eea",
   "metadata": {},
   "source": [
    "# 3.读取所有的影像数据并拼接为一个numpy矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "682e4069-d3a7-473d-bf98-eac55cd509fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./NPP\\NPP_2002.tif\n",
      "./NPP\\NPP_2003.tif\n",
      "./NPP\\NPP_2004.tif\n",
      "./NPP\\NPP_2005.tif\n",
      "./NPP\\NPP_2006.tif\n",
      "./NPP\\NPP_2007.tif\n",
      "./NPP\\NPP_2008.tif\n",
      "./NPP\\NPP_2009.tif\n",
      "./NPP\\NPP_2010.tif\n",
      "./NPP\\NPP_2011.tif\n",
      "./NPP\\NPP_2012.tif\n",
      "./NPP\\NPP_2013.tif\n",
      "./NPP\\NPP_2014.tif\n",
      "./NPP\\NPP_2015.tif\n",
      "./NPP\\NPP_2016.tif\n",
      "./NPP\\NPP_2017.tif\n",
      "./NPP\\NPP_2018.tif\n",
      "./NPP\\NPP_2019.tif\n",
      "./NPP\\NPP_2020.tif\n",
      "./NPP\\NPP_2021.tif\n",
      "./NPP\\NPP_2022.tif\n"
     ]
    }
   ],
   "source": [
    "#获取影像数量\n",
    "num_images=len(filepaths)\n",
    "#读取影像数据\n",
    "img1=ras.open(filepaths[0])\n",
    "#获取影像的投影，高度和宽度\n",
    "transform1=img1.transform\n",
    "height1=img1.height\n",
    "width1=img1.width \n",
    "array1=img1.read()\n",
    "img1.close()\n",
    "\n",
    "#读取所有影像\n",
    "for path1 in filepaths[1:]:\n",
    "    if path1[-3:]=='tif':\n",
    "        print(path1)\n",
    "        img2=ras.open(path1)\n",
    "        array2=img2.read()\n",
    "        array1=np.vstack((array1,array2))\n",
    "        img2.close()\n",
    "    \n",
    "nums,width,height=array1.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1eebdb-19ff-4263-b771-cc3d70af0fa0",
   "metadata": {},
   "source": [
    "# 4.定义输出矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf564f5-cc35-460f-bc5d-cf10a89cfe76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the pixel counts are 762660\n"
     ]
    }
   ],
   "source": [
    "#输出矩阵，无值区用-9999填充    \n",
    "slope_array=np.full([width,height],-9999.0000) \n",
    "z_array=np.full([width,height],-9999.0000)\n",
    "Trend_array=np.full([width,height],-9999.0000) \n",
    "Tau_array=np.full([width,height],-9999.0000)\n",
    "s_array=np.full([width,height],-9999.0000)\n",
    "p_array=np.full([width,height],-9999.0000)\n",
    "#只有有值的区域才进行mk检验，如果所有影像同一像元都为空，则不进行mk检验\n",
    "c1=np.isnan(array1)\n",
    "sum_array1=np.sum(c1,axis=0)\n",
    "nan_positions=np.where(sum_array1==num_images)\n",
    "positions=np.where(sum_array1!=num_images) \n",
    "#输出总像元数量\n",
    "print(\"all the pixel counts are {0}\".format(len(positions[0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908ae6f-c97d-4001-8f6a-f21c9c175fe6",
   "metadata": {},
   "source": [
    "# 5.sen+mk检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f37f7d6-02b4-4f9b-a850-2868ddb657ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m y\u001b[38;5;241m=\u001b[39mpositions[\u001b[38;5;241m1\u001b[39m][i]    \n\u001b[0;32m      5\u001b[0m mk_list1\u001b[38;5;241m=\u001b[39marray1[:,x,y]\n\u001b[1;32m----> 6\u001b[0m trend, h, p, z, Tau, s, var_s, slope, intercept  \u001b[38;5;241m=\u001b[39m \u001b[43mmk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moriginal_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmk_list1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trend\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecreasing\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      8\u001b[0m     trend_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mE:\\Geo_Data\\venv\\lib\\site-packages\\pymannkendall\\pymannkendall.py:253\u001b[0m, in \u001b[0;36moriginal_test\u001b[1;34m(x_old, alpha)\u001b[0m\n\u001b[0;32m    251\u001b[0m s \u001b[38;5;241m=\u001b[39m __mk_score(x, n)\n\u001b[0;32m    252\u001b[0m var_s \u001b[38;5;241m=\u001b[39m __variance_s(x, n)\n\u001b[1;32m--> 253\u001b[0m Tau \u001b[38;5;241m=\u001b[39m \u001b[43ms\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m.5\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m z \u001b[38;5;241m=\u001b[39m __z_score(s, var_s)\n\u001b[0;32m    256\u001b[0m p, h, trend \u001b[38;5;241m=\u001b[39m __p_value(z, alpha)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "for i in range(len(positions[0])):\n",
    "    print(i)\n",
    "    x=positions[0][i]\n",
    "    y=positions[1][i]    \n",
    "    mk_list1=array1[:,x,y]\n",
    "    trend, h, p, z, Tau, s, var_s, slope, intercept  = mk.original_test(mk_list1)\n",
    "    if trend==\"decreasing\":\n",
    "        trend_value=-1\n",
    "    elif trend==\"increasing\":\n",
    "        trend_value=1\n",
    "    else:\n",
    "        trend_value=0\n",
    "    slope_array[x,y]=slope#senslope\n",
    "    s_array[x,y]=s\n",
    "    z_array[x,y]=z\n",
    "    Trend_array[x,y]=trend_value\n",
    "    p_array[x,y]=p\n",
    "    Tau_array[x,y]=Tau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88be5e4-1c7b-41f0-a911-fa464e6fcc38",
   "metadata": {},
   "source": [
    "# 6.定义写影像的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb58d95c-0950-4807-9a42-1de129400d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#写影像，包括宽度，高度，投影，波段名，矩阵\n",
    "def writeImage(image_save_path,height1,width1,para_array,bandDes,transform1):\n",
    "    with ras.open(\n",
    "           image_save_path,\n",
    "           'w',\n",
    "           driver='GTiff',\n",
    "           height=height1,\n",
    "           width=width1,\n",
    "           count=1,\n",
    "           dtype=para_array.dtype,\n",
    "           crs='+proj=latlong',\n",
    "           transform=transform1,\n",
    "    ) as dst:\n",
    "               dst.write_band(1,para_array)\n",
    "               dst.set_band_description(1,bandDes)\n",
    "    del dst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bace351-593f-4681-ac4c-2092a3ba5a6b",
   "metadata": {},
   "source": [
    "# 7.输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47a728c-cb9e-479a-83bd-82176793cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#输出矩阵\n",
    "all_array=[slope_array,Trend_array,p_array,s_array,Tau_array,z_array]   \n",
    "#输出路径\n",
    "result_path=r\"E:\\2021-03-03—生态修复\\吴起本地\\result\"\n",
    "slope_save_path=os.path.join(result_path,\"slope.tif\")\n",
    "Trend_save_path=os.path.join(result_path,\"Trend.tif\")\n",
    "p_save_path=os.path.join(result_path,\"p.tif\")\n",
    "s_save_path=os.path.join(result_path,\"s.tif\")\n",
    "tau_save_path=os.path.join(result_path,\"tau.tif\")\n",
    "z_save_path=os.path.join(result_path,\"z.tif\")\n",
    "image_save_paths=[slope_save_path,Trend_save_path,p_save_path,s_save_path,tau_save_path,z_save_path]\n",
    "band_Des=['slope','trend','p_value','score','tau','z_value']\n",
    "#逐个存储\n",
    "for i in range(len(all_array)):\n",
    "    writeImage(image_save_paths[i], height1, width1, all_array[i], band_Des[i],transform1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528472db-c208-4f0d-bfad-072c7dada7a1",
   "metadata": {},
   "source": [
    "# 汇总"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa6044e-e284-41d4-afff-e39a8de7e216",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./NPP_test\\NPP_2002.tif\n",
      "./NPP_test\\NPP_2003.tif\n",
      "./NPP_test\\NPP_2004.tif\n",
      "./NPP_test\\NPP_2005.tif\n",
      "./NPP_test\\NPP_2006.tif\n",
      "./NPP_test\\NPP_2007.tif\n",
      "./NPP_test\\NPP_2008.tif\n",
      "./NPP_test\\NPP_2009.tif\n",
      "./NPP_test\\NPP_2010.tif\n",
      "./NPP_test\\NPP_2011.tif\n",
      "./NPP_test\\NPP_2012.tif\n",
      "./NPP_test\\NPP_2013.tif\n",
      "./NPP_test\\NPP_2014.tif\n",
      "./NPP_test\\NPP_2015.tif\n",
      "./NPP_test\\NPP_2016.tif\n",
      "./NPP_test\\NPP_2017.tif\n",
      "./NPP_test\\NPP_2018.tif\n",
      "./NPP_test\\NPP_2019.tif\n",
      "./NPP_test\\NPP_2020.tif\n",
      "./NPP_test\\NPP_2021.tif\n",
      "./NPP_test\\NPP_2022.tif\n",
      "all the pixel counts are 45135\n",
      "完成!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Created on 2021年4月11日\n",
    "\n",
    "@author: SunStrong\n",
    "'''\n",
    "#coding:utf-8\n",
    "import numpy as np\n",
    "import pymannkendall as mk\n",
    "import os \n",
    "import rasterio as ras\n",
    "\n",
    "\n",
    "\n",
    "def sen_mk_test(image_path,outputPath):\n",
    "    \n",
    "    #image_path:影像的存储路径\n",
    "    #outputPath:结果输出路径\n",
    "    \n",
    "    filepaths=[]\n",
    "    for file in os.listdir(image_path):\n",
    "        filepath1=os.path.join(image_path,file)\n",
    "        filepaths.append(filepath1)\n",
    "    \n",
    "    #获取影像数量\n",
    "    num_images=len(filepaths)\n",
    "    #读取影像数据\n",
    "    img1=ras.open(filepaths[0])\n",
    "    #获取影像的投影，高度和宽度\n",
    "    transform1=img1.transform\n",
    "    height1=img1.height\n",
    "    width1=img1.width \n",
    "    array1=img1.read()\n",
    "    img1.close()\n",
    "    \n",
    "    #读取所有影像\n",
    "    for path1 in filepaths[1:]:\n",
    "        if path1[-3:]=='tif':\n",
    "            print(path1)\n",
    "            img2=ras.open(path1)\n",
    "            array2=img2.read()\n",
    "            array1=np.vstack((array1,array2))\n",
    "            img2.close()\n",
    "        \n",
    "    nums,width,height=array1.shape \n",
    "    #写影像\n",
    "    def writeImage(image_save_path,height1,width1,para_array,bandDes,transform1):\n",
    "        with ras.open(\n",
    "               image_save_path,\n",
    "               'w',\n",
    "               driver='GTiff',\n",
    "               height=height1,\n",
    "               width=width1,\n",
    "               count=1,\n",
    "               dtype=para_array.dtype,\n",
    "               crs='+proj=latlong',\n",
    "               transform=transform1,\n",
    "        ) as dst:\n",
    "                   dst.write_band(1,para_array)\n",
    "                   dst.set_band_description(1,bandDes)\n",
    "        del dst\n",
    "    \n",
    "    #输出矩阵，无值区用-9999填充    \n",
    "    slope_array=np.full([width,height],-9999.0000) \n",
    "    z_array=np.full([width,height],-9999.0000)\n",
    "    Trend_array=np.full([width,height],-9999.0000) \n",
    "    Tau_array=np.full([width,height],-9999.0000)\n",
    "    s_array=np.full([width,height],-9999.0000)\n",
    "    p_array=np.full([width,height],-9999.0000)\n",
    "    #只有有值的区域才进行mk检验\n",
    "    c1=np.isnan(array1)\n",
    "    sum_array1=np.sum(c1,axis=0)\n",
    "    nan_positions=np.where(sum_array1==num_images)\n",
    "    \n",
    "    positions=np.where(sum_array1!=num_images) \n",
    "    \n",
    "    \n",
    "    #输出总像元数量\n",
    "    print(\"all the pixel counts are {0}\".format(len(positions[0])))\n",
    "    #mk test\n",
    "    for i in range(len(positions[0])):\n",
    "        # print(i)\n",
    "        x=positions[0][i]\n",
    "        y=positions[1][i]    \n",
    "        mk_list1=array1[:,x,y]\n",
    "        # 跳过无效值\n",
    "        if np.isnan(mk_list1).any():\n",
    "            continue\n",
    "        trend, h, p, z, Tau, s, var_s, slope, intercept  = mk.original_test(mk_list1)\n",
    "        '''        \n",
    "        trend: tells the trend (increasing, decreasing or no trend)\n",
    "                h: True (if trend is present) or False (if trend is absence)\n",
    "                p: p-value of the significance test\n",
    "                z: normalized test statistics\n",
    "                Tau: Kendall Tau\n",
    "                s: Mann-Kendal's score\n",
    "                var_s: Variance S\n",
    "                slope: Theil-Sen estimator/slope\n",
    "                intercept: intercept of Kendall-Theil Robust Line\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        if trend==\"decreasing\":\n",
    "            trend_value=-1\n",
    "        elif trend==\"increasing\":\n",
    "            trend_value=1\n",
    "        else:\n",
    "            trend_value=0\n",
    "        slope_array[x,y]=slope#senslope\n",
    "        s_array[x,y]=s\n",
    "        z_array[x,y]=z\n",
    "        Trend_array[x,y]=trend_value\n",
    "        p_array[x,y]=p\n",
    "        Tau_array[x,y]=Tau \n",
    "        \n",
    "        \n",
    "    all_array=[slope_array,Trend_array,p_array,s_array,Tau_array,z_array]   \n",
    "    \n",
    "    slope_save_path=os.path.join(result_path,\"slope.tif\")\n",
    "    Trend_save_path=os.path.join(result_path,\"Trend.tif\")\n",
    "    p_save_path=os.path.join(result_path,\"p.tif\")\n",
    "    s_save_path=os.path.join(result_path,\"s.tif\")\n",
    "    tau_save_path=os.path.join(result_path,\"tau.tif\")\n",
    "    z_save_path=os.path.join(result_path,\"z.tif\")\n",
    "    image_save_paths=[slope_save_path,Trend_save_path,p_save_path,s_save_path,tau_save_path,z_save_path]\n",
    "    band_Des=['slope','trend','p_value','score','tau','z_value']\n",
    "    for i in range(len(all_array)):\n",
    "        writeImage(image_save_paths[i], height1, width1, all_array[i], band_Des[i],transform1)\n",
    "\n",
    "#调用\n",
    "path = \"./NPP_test\"\n",
    "result_path = \"./result1\"\n",
    "sen_mk_test(path, result_path)\n",
    "print(\"完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b63a25-e915-4810-a866-801fe8cef9fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./NPP\\NPP_2002.tif\n",
      "./NPP\\NPP_2003.tif\n",
      "./NPP\\NPP_2004.tif\n",
      "./NPP\\NPP_2005.tif\n",
      "./NPP\\NPP_2006.tif\n",
      "./NPP\\NPP_2007.tif\n",
      "./NPP\\NPP_2008.tif\n",
      "./NPP\\NPP_2009.tif\n",
      "./NPP\\NPP_2010.tif\n",
      "./NPP\\NPP_2011.tif\n",
      "./NPP\\NPP_2012.tif\n",
      "./NPP\\NPP_2013.tif\n",
      "./NPP\\NPP_2014.tif\n",
      "./NPP\\NPP_2015.tif\n",
      "./NPP\\NPP_2016.tif\n",
      "./NPP\\NPP_2017.tif\n",
      "./NPP\\NPP_2018.tif\n",
      "./NPP\\NPP_2019.tif\n",
      "./NPP\\NPP_2020.tif\n",
      "./NPP\\NPP_2021.tif\n",
      "./NPP\\NPP_2022.tif\n",
      "all the pixel counts are 762660\n",
      "完成!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Created on 2021年4月11日\n",
    "\n",
    "@author: SunStrong\n",
    "'''\n",
    "#coding:utf-8\n",
    "import numpy as np\n",
    "import pymannkendall as mk\n",
    "import os \n",
    "import rasterio as ras\n",
    "\n",
    "\n",
    "\n",
    "def sen_mk_test(image_path,outputPath):\n",
    "    \n",
    "    #image_path:影像的存储路径\n",
    "    #outputPath:结果输出路径\n",
    "    \n",
    "    filepaths=[]\n",
    "    for file in os.listdir(image_path):\n",
    "        filepath1=os.path.join(image_path,file)\n",
    "        filepaths.append(filepath1)\n",
    "    \n",
    "    #获取影像数量\n",
    "    num_images=len(filepaths)\n",
    "    #读取影像数据\n",
    "    img1=ras.open(filepaths[0])\n",
    "    #获取影像的投影，高度和宽度\n",
    "    transform1=img1.transform\n",
    "    height1=img1.height\n",
    "    width1=img1.width \n",
    "    array1=img1.read()\n",
    "    img1.close()\n",
    "    \n",
    "    #读取所有影像\n",
    "    for path1 in filepaths[1:]:\n",
    "        if path1[-3:]=='tif':\n",
    "            print(path1)\n",
    "            img2=ras.open(path1)\n",
    "            array2=img2.read()\n",
    "            array1=np.vstack((array1,array2))\n",
    "            img2.close()\n",
    "        \n",
    "    nums,width,height=array1.shape \n",
    "    #写影像\n",
    "    def writeImage(image_save_path,height1,width1,para_array,bandDes,transform1):\n",
    "        with ras.open(\n",
    "               image_save_path,\n",
    "               'w',\n",
    "               driver='GTiff',\n",
    "               height=height1,\n",
    "               width=width1,\n",
    "               count=1,\n",
    "               dtype=para_array.dtype,\n",
    "               crs='+proj=latlong',\n",
    "               transform=transform1,\n",
    "        ) as dst:\n",
    "                   dst.write_band(1,para_array)\n",
    "                   dst.set_band_description(1,bandDes)\n",
    "        del dst\n",
    "    \n",
    "    #输出矩阵，无值区用np.nan填充    \n",
    "    slope_array=np.full([width,height],np.nan) \n",
    "    z_array=np.full([width,height],np.nan)\n",
    "    Trend_array=np.full([width,height],np.nan) \n",
    "    Tau_array=np.full([width,height],np.nan)\n",
    "    s_array=np.full([width,height],np.nan)\n",
    "    p_array=np.full([width,height],np.nan)\n",
    "    #只有有值的区域才进行mk检验\n",
    "    c1=np.isnan(array1)\n",
    "    sum_array1=np.sum(c1,axis=0)\n",
    "    nan_positions=np.where(sum_array1==num_images)\n",
    "    \n",
    "    positions=np.where(sum_array1!=num_images) \n",
    "    \n",
    "    \n",
    "    #输出总像元数量\n",
    "    print(\"all the pixel counts are {0}\".format(len(positions[0])))\n",
    "    #mk test\n",
    "    for i in range(len(positions[0])):\n",
    "        # print(i)\n",
    "        x=positions[0][i]\n",
    "        y=positions[1][i]    \n",
    "        mk_list1=array1[:,x,y]\n",
    "        # 跳过无效值\n",
    "        if np.isnan(mk_list1).any():\n",
    "            continue\n",
    "        trend, h, p, z, Tau, s, var_s, slope, intercept  = mk.original_test(mk_list1)\n",
    "        '''        \n",
    "        trend: tells the trend (increasing, decreasing or no trend)\n",
    "                h: True (if trend is present) or False (if trend is absence)\n",
    "                p: p-value of the significance test\n",
    "                z: normalized test statistics\n",
    "                Tau: Kendall Tau\n",
    "                s: Mann-Kendal's score\n",
    "                var_s: Variance S\n",
    "                slope: Theil-Sen estimator/slope\n",
    "                intercept: intercept of Kendall-Theil Robust Line\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        if trend==\"decreasing\":\n",
    "            trend_value=-1\n",
    "        elif trend==\"increasing\":\n",
    "            trend_value=1\n",
    "        else:\n",
    "            trend_value=0\n",
    "        slope_array[x,y]=slope#senslope\n",
    "        s_array[x,y]=s\n",
    "        z_array[x,y]=z\n",
    "        Trend_array[x,y]=trend_value\n",
    "        p_array[x,y]=p\n",
    "        Tau_array[x,y]=Tau \n",
    "        \n",
    "        \n",
    "    all_array=[slope_array,Trend_array,p_array,s_array,Tau_array,z_array]   \n",
    "    \n",
    "    slope_save_path=os.path.join(result_path,\"slope.tif\")\n",
    "    Trend_save_path=os.path.join(result_path,\"Trend.tif\")\n",
    "    p_save_path=os.path.join(result_path,\"p.tif\")\n",
    "    s_save_path=os.path.join(result_path,\"s.tif\")\n",
    "    tau_save_path=os.path.join(result_path,\"tau.tif\")\n",
    "    z_save_path=os.path.join(result_path,\"z.tif\")\n",
    "    image_save_paths=[slope_save_path,Trend_save_path,p_save_path,s_save_path,tau_save_path,z_save_path]\n",
    "    band_Des=['slope','trend','p_value','score','tau','z_value']\n",
    "    for i in range(len(all_array)):\n",
    "        writeImage(image_save_paths[i], height1, width1, all_array[i], band_Des[i],transform1)\n",
    "\n",
    "#调用\n",
    "path = \"./NPP\"\n",
    "result_path = \"./result\"\n",
    "sen_mk_test(path, result_path)\n",
    "print(\"完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989ce42b-adf7-44cb-9653-512fe1e14475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
